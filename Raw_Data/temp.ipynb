{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a7e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DieAntwoord.csv: 74\n",
      "JPEGMAFIA.csv: 108\n",
      "WittLowry.csv: 62\n",
      "bjork.csv: 83\n",
      "charlesaznavour.csv: 54\n",
      "duster.csv: 68\n",
      "gangstarr.csv: 86\n",
      "goonrock.csv: 2\n",
      "justinskye.csv: 51\n",
      "kenyagrace.csv: 18\n",
      "kyan.csv: 9\n",
      "mako.csv: 20\n",
      "markmorrison.csv: 11\n",
      "maydayparade.csv: 78\n",
      "metronomy.csv: 50\n",
      "natalieimbruglia.csv: 67\n",
      "reneeelisegoldsberry.csv: 14\n",
      "roar.csv: 32\n",
      "stevieray vaughan.csv: 42\n",
      "thehollies.csv: 220\n",
      "troy.csv: 11\n",
      "vigiland.csv: 16\n",
      "Total rows across all CSV files: 1176\n"
     ]
    }
   ],
   "source": [
    "# cell 0 - count rows in all CSV files in current folder and print per-file counts + total\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "def count_csv_rows(path):\n",
    "    try:\n",
    "        with path.open(newline='', encoding='utf-8') as f:\n",
    "            return sum(1 for _ in csv.reader(f))\n",
    "    except UnicodeDecodeError:\n",
    "        with path.open(newline='', encoding='latin-1') as f:\n",
    "            return sum(1 for _ in csv.reader(f))\n",
    "\n",
    "p = Path('.')\n",
    "csv_files = sorted(p.glob('*.csv'))\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in current folder.\")\n",
    "else:\n",
    "    totals = {}\n",
    "    for f in csv_files:\n",
    "        rows = count_csv_rows(f)\n",
    "        totals[f.name] = rows\n",
    "        print(f\"{f.name}: {rows}\")\n",
    "    total_sum = sum(totals.values())\n",
    "    print(\"Total rows across all CSV files:\", total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30550950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset created: balanced_master.csv\n",
      "Final shape: (1000, 9)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # File names and final target record counts\n",
    "# files_targets = {\n",
    "#     \"Billie_Ilish.csv\": 41,\n",
    "#     \"Drake.csv\": 87,\n",
    "#     \"Ed_Sheeran.csv\": 86,\n",
    "#     \"Eminem.csv\": 100,\n",
    "#     \"Justin_Bieber.csv\": 96,\n",
    "#     \"Kanye_West.csv\": 86,\n",
    "#     \"Kendrick_Lamar.csv\": 97,\n",
    "#     \"Postmalone.csv\": 63,\n",
    "#     \"Rihanna.csv\": 90,\n",
    "#     \"Taylor_Swift.csv\": 87,\n",
    "#     \"The_Weeknd.csv\": 86,\n",
    "#     \"Travis_Scott.csv\": 86\n",
    "# }\n",
    "\n",
    "# master_df = []\n",
    "\n",
    "# for file, target_count in files_targets.items():\n",
    "#     # Load CSV\n",
    "#     df = pd.read_csv(file)\n",
    "\n",
    "#     # Shuffle so selection is random\n",
    "#     df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#     # Trim to the required number of rows\n",
    "#     df = df.head(target_count)\n",
    "\n",
    "#     # Add artist column (file name without .csv)\n",
    "#     artist_name = file.replace(\".csv\", \"\")\n",
    "#     df[\"artist\"] = artist_name\n",
    "\n",
    "#     master_df.append(df)\n",
    "\n",
    "# # Combine all final trimmed data\n",
    "# balanced_master = pd.concat(master_df, ignore_index=True)\n",
    "\n",
    "# # Save final dataset\n",
    "# balanced_master.to_csv(\"balanced_master.csv\", index=False)\n",
    "\n",
    "# print(\"Balanced dataset created: balanced_master.csv\")\n",
    "# print(\"Final shape:\", balanced_master.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa9df5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully combined all CSV files into master_df.csv\n",
      "Final shape of the master dataframe: (1152, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "master_df_list = []\n",
    "\n",
    "for f in csv_files:\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df_temp = pd.read_csv(f)\n",
    "        \n",
    "        # Extract artist name from filename\n",
    "        artist_name = f.stem\n",
    "        \n",
    "        # Add the 'artist' column\n",
    "        df_temp['artist'] = artist_name\n",
    "        \n",
    "        # Append the dataframe to our list\n",
    "        master_df_list.append(df_temp)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not process file {f.name}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes in the list into one\n",
    "if master_df_list:\n",
    "    master_df = pd.concat(master_df_list, ignore_index=True)\n",
    "\n",
    "    # Save the combined dataframe to a new CSV file\n",
    "    master_df.to_csv(\"master_df.csv\", index=False)\n",
    "\n",
    "    print(\"Successfully combined all CSV files into master_df.csv\")\n",
    "    print(\"Final shape of the master dataframe:\", master_df.shape)\n",
    "else:\n",
    "    print(\"No dataframes were created to combine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f677f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18e8a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1152 entries, 0 to 1151\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   SongName   1152 non-null   object\n",
      " 1   AlbumName  1152 non-null   object\n",
      " 2   AlbumLink  1152 non-null   object\n",
      " 3   Year       1152 non-null   int64 \n",
      " 4   PlayCount  1152 non-null   int64 \n",
      " 5   Lyrics     1152 non-null   object\n",
      " 6   SongLink   1152 non-null   object\n",
      " 7   Duration   1152 non-null   int64 \n",
      " 8   artist     1152 non-null   object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 81.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"master_df.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2901ffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist\n",
      "thehollies              219\n",
      "JPEGMAFIA               107\n",
      "gangstarr                85\n",
      "bjork                    82\n",
      "maydayparade             77\n",
      "DieAntwoord              73\n",
      "duster                   67\n",
      "natalieimbruglia         66\n",
      "WittLowry                61\n",
      "charlesaznavour          53\n",
      "justinskye               50\n",
      "metronomy                49\n",
      "stevieray vaughan        41\n",
      "roar                     31\n",
      "mako                     19\n",
      "kenyagrace               15\n",
      "vigiland                 15\n",
      "reneeelisegoldsberry     13\n",
      "markmorrison             10\n",
      "troy                     10\n",
      "kyan                      8\n",
      "goonrock                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['artist'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b17928aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ebba5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1152 lyric files to Low Artists\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"Low Artists\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def sanitize_filename(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[\\\\/*?:\"<>|]', \"\", s)  # remove illegal filename chars\n",
    "    s = re.sub(r'\\s+', '_', s)  # replace whitespace with underscore\n",
    "    return s[:200]  # cap length to avoid OS limits\n",
    "\n",
    "seen = {}\n",
    "count = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    artist = str(row.get(\"artist\", \"\")).strip()\n",
    "    song = str(row.get(\"SongName\", \"\")).strip()\n",
    "    lyrics = row.get(\"Lyrics\", \"\")\n",
    "\n",
    "    a = sanitize_filename(artist) or \"unknown_artist\"\n",
    "    s = sanitize_filename(song) or f\"song_{idx}\"\n",
    "\n",
    "    base_name = f\"{a}_{s}.txt\"\n",
    "    if base_name in seen:\n",
    "        seen[base_name] += 1\n",
    "        filename = f\"{a}_{s}_{seen[base_name]}.txt\"\n",
    "    else:\n",
    "        seen[base_name] = 0\n",
    "        filename = base_name\n",
    "\n",
    "    path = out_dir / filename\n",
    "    path.write_text(str(lyrics), encoding=\"utf-8\")\n",
    "    count += 1\n",
    "\n",
    "print(f\"Saved {count} lyric files to {out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3583c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Using the 'df' DataFrame which is already loaded with 'balanced_master.csv'\n",
    "df = pd.read_csv(\"WittLowry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a4c87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SongName'] = df['SongName'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "716b6670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for partial duplicate song names...\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 0, Name: ALONE\n",
      "   Match: Index 19, Name: Hurt Alone\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 18, Name: HURT\n",
      "   Match: Index 19, Name: Hurt Alone\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the 'SongName' column and its corresponding indices\n",
    "songs = df['SongName'].tolist()\n",
    "indices = df.index.tolist()\n",
    "\n",
    "# A set to keep track of printed indices to avoid duplicate reports\n",
    "reported_indices = set()\n",
    "\n",
    "print(\"Checking for partial duplicate song names...\")\n",
    "\n",
    "# Iterate through each song and compare it with every other song\n",
    "for i in range(len(songs)):\n",
    "    # Skip if this song has already been reported as a duplicate\n",
    "    if i in reported_indices:\n",
    "        continue\n",
    "\n",
    "    # Clean up the first song name\n",
    "    s1 = str(songs[i]).strip().lower()\n",
    "    \n",
    "    # List to hold matches for the current song\n",
    "    matches = []\n",
    "\n",
    "    # Compare with subsequent songs\n",
    "    for j in range(i + 1, len(songs)):\n",
    "        # Clean up the second song name\n",
    "        s2 = str(songs[j]).strip().lower()\n",
    "\n",
    "        # Check for partial match (substring)\n",
    "        if s1 in s2 or s2 in s1:\n",
    "            matches.append(j)\n",
    "\n",
    "    # If any matches were found for song s1\n",
    "    if matches:\n",
    "        print(\"\\n--- Match Found ---\")\n",
    "        print(f\"Original: Index {indices[i]}, Name: {songs[i]}\")\n",
    "        reported_indices.add(i)\n",
    "        for match_idx in matches:\n",
    "            print(f\"   Match: Index {indices[match_idx]}, Name: {songs[match_idx]}\")\n",
    "            reported_indices.add(match_idx)\n",
    "\n",
    "if not reported_indices:\n",
    "    print(\"No partial duplicates found in 'SongName' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f91bfed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the row at index 100\n",
    "df = df.drop(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c79b21d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of the DataFrame: (15, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(\"kenyagrace.csv\", index=False)\n",
    "print(\"New shape of the DataFrame:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8d30e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
